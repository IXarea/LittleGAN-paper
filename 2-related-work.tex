\section{Related Work}

In order to achieve the purpose of efficiently generating high-quality faces that meet the needs of people, on one hand,
    it is necessary to properly handle the input and still maintain some features of the original image after adjusting the specific attributes of the face image for multiple times.
On the other hand, train faces to get a more efficient model.

With the development of machine learning, there are related researches on face synthesis in computer research.
Below we briefly introduce related work at home and abroad.

%todo: Need to reconstruct
\subsection{Facial Image Generation}

\paragraph{Image Generation}

Image generation is the basis of facial image generation.
Text-to-Image\upcite{text2img} proposed the generation of texts to images earlier.
Based on DCGAN\upcite{dcgan}, they embed the text descriptions into words and combine them with noise vectors to generate images through convolution operations.
In StackGAN\upcite{stackgan}, the author also embeds the text description into the text feature vector,
    and initially generates the contour of the object,
    and further combines the text feature vector to generate higher resolution and more detailed images.
    InfoGAN is able to extract attributes from images, enabling conditional generation of images and unsupervised learning.
They also use different discriminators to identify images at different stages, thereby improving the quality of the image.


\paragraph{Facial Image Generation}

At present, there are several models related to the improvement of image generation quality,
    such as BEGAN\upcite{began} and PGGAN\upcite{pggan}.
BEGAN\upcite{began} uses a generator and a discriminator similar to the variational auto-encoding to improve the resolution of the image and the diversity of image generation by sequentially convolving the image,
    maintaining the stability of image generation.
PGGAN\upcite{pggan} first trains low-resolution faces,
    and gradually increases the network layer for training,
    therefore improving the resolution of the model output image and the stability of the network.



\subsection{Facial Image Adjustment}

\paragraph{Image Translation}
Image generation is the basis of facial image generation.
Image translation treats the image as outputs and the purpose of changing the image attributes is achieved by converting the attributes(or domains).
Pix2pix\upcite{pix2pix} uses the U-Net network, L1 Loss and PatchGAN classifiers.
In the generator, U-Net combines Encoder with Decoder,
    reducing the pressure on each network layer and retaining more image information.
In the discriminator they use L1 Loss to globally constrain the image.
In the partial adjustment of the image,
    they use PatchGAN to discriminate image so that improve the quality of image.
Therefore, each layer of convolution convolution combines the local characteristics of the corresponding layer before convolution,
    and pix2pix\upcite{pix2pix} can generate images better.
CycleGAN\upcite{cyclegan} uses two generators and two discriminators to train separately achieving image conversion between the two attribute domains.
Whether it is pix2pix\upcite{pix2pix} or CycleGAN\upcite{cyclegan},
    although they can achieve the purpose of converting image attributes better,
    it is limited to two definite domains.
If it is required to convert multiple attributes, multiple models are needed.
In that case, the size of the model and the amount of calculation are too large to meet the actual needs of people.

\paragraph{Facial Image Adjustment}
StarGAN\upcite{stargan} trains across data sets so that the model can learn attributes and features from multiple data sets,
    and can generate images by specifying more attributes.
AttGAN\upcite{attgan} extracts the attributes and latent vectors of the image,
    changes the attributes and combines the latent vectors to generate an image,
    thus realizing the adjustment of the image.
Pix2pixHD\upcite{pix2pixhd} uses multiple discriminators to discriminating images of different resolutions,
    and finally combines features at different resolutions to generate high-resolution face images.
However, this model is huge and difficult to train.
Apart from that, it is too expensive to deploy and operate.
Addtionally, the process of extracting the latent vector would cause information loss.
So some features of the original image will be lost in the new image.
The research on multi-angle transformation of facial images is mainly based on the generation of positive faces based on the human face.
The main method of this research is to build a face frame and then generate details.
Taking TPGAN\upcite{tpgan} as an example, TPGAN\upcite{tpgan} uses a variety of Loss,
    which not only achieves the multi-angle transformation of the face,
    but also achieves the purpose of repairing the images and improving the resolution of the facial image.

\vspace{3ex}

From the above analysis of the current situation,
    we can learn that the current facial image generation and face image adjustment in the face research are generally separated.
Also, different models are required to be used.
Moreover, the image attribute extraction process need to be through different models.
The conversion of the model is likely to cause certain information loss.
Therefore, we hope to use a model to complete the two tasks of face image generation and face image adjustment so that not only the network layer parameters of the extracted image features can be shared,
    but also the time and power consumption in the training model can be reduced.
During the generation and adjustment process, the attribute parameters are unified,
    avoiding the extra consumption caused by the conversion between different models.