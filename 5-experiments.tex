\section{Experiments}

\subsection{Experiments Setup}
The Ubuntu 16.04 x64 operating system is used in this study, using the Python programming language version 3.6.6, based on the Tensorflow 1.11 and Keras 2.2.4 frameworks. The model is trained using an NVIDIA TITAN X (Pascal) graphics card in each experiment.

\subsection{Dataset}
We use the public dataset CelebA\upcite{celeba}, which contains a total of 202,599 face images, and label 40 attributes for each face. We align and crop the faces in all images into RGB three-channel images of 128 Ã— 128 pixels and then divide them into training sets, test sets, and verification sets according to the ratio of 8:1:1. 
For the 40 attributes in the dataset, we selecte 4 of them: 'gender', 'skin color', 'hair color', 'beard' attribute to verify the feasibility of the model.

\subsection{Experimental projects}
\begin{itemize}
\item In order to obtain a suitable model structure and training hyperparameters, we designed multiple sets of comparative experiments to test the effects of different improvement projects.
\item In order to verify that our model can generate face images with high realism according to input conditions, and it has practicability, we set up the experiment of generating and adjusting face images.
\item To prove that our method is cheaper to use, we also set up a set of model volume comparison experiments.
\end{itemize}

\subsection{Training details}
We use the Adam\upcite{adam} optimizer to optimize the network. The learning rates of the discriminator, generator and auto-encoder network are set to 0.0001, 0.00015 and 0.00005, respectively.
 Beta1 and beta2 select the default configuration in Adam's\upcite{adam} paper, which is respectively 0.5 and 0.9. The encoder network is fixed when training the auto-encoder network.
  The $\lambda$ in both the generator and the auto-encoder network is set to 0.05, using 100-dimensional latent vector input, each batch uses a random 32 training set images for training and a total of 25 training sessions are used. 
 In each batch, the generator is used to generate the image first. Then the discriminator is used to identify the image and adjusted by the auto-encoder network.
 The calculation results above are on gradient penalization and the respective losses of the discriminator, the generator, and the auto-encoder network are calculated. Then the respective optimizers separately performs backpropagation and optimizes network weight parameters. In the part training, the overall model training and the part training are performed in a 4:1 ratio.

\subsection{Experiments Result}
